[[2024-03-28]]

## 基本概念
知识图谱嵌入 (knowledge graph embedding, KGE) 或知识表示学习 (knowledge representation learning, KRL), 旨在将 KG 的组成部分 (包括实体和关系) 嵌入到连续的向量空间中, 以在简化操作的同时保留 KG 的固有结构. 
与传统的表示方法相比, KGE 为 KG 中的实体和关系提供了更加密集的表示, 降低了其应用中的计算复杂度. 此外, KGE 可以通过度量实体和关系低维嵌入的相似性 来显式地捕获实体和关系之间的相似性.
知识图谱嵌入主要思想:
**将知识图谱中的实体和关系嵌入到连续的向量空间中, 用来简化操作, 同时保留 KG 的固有结构. 可以使得多种下游任务受益**

## 使用事实进行知识图谱嵌入

本节对仅使用事实进行知识图谱嵌入的方法采用评分函数进行划分. **评分函数用于衡量事实的合理性**, 在基 于能量的学习框架中也被称为能量函数. 典型类型的评分函数分为两种: **基于距离**的评分函数 (如图 1(a)) 与**基于相似性**的评分函数 (如图 1(b)).
![[Pasted image 20240328170928.png]]
### 基于距离的模型
翻译原理  $h+r\approx t$ 被广泛使用. 也就是说, 基于距离的模型通常由关系执行翻译后, 根据两个实体之间的距离来度 量一个事实的合理性.
#### structured embedding(SE)
每个实体用 $d$ 维向量表示, SE 为每个关系定义了两个投影矩阵 $M_{r_,1}$和 $M_{r,2}$ , 利用 这两个投影矩阵和 距离学习结构嵌入为:$$f_r\left(h,t\right)=-\left\|\mathbf{M}_{r,1}h-\mathbf{M}_{r,2}t\right\|_1$$
### Trans系列
![[Pasted image 20240328172004.png]]
#### TransE

给定事实  , 关系 $r$的向量 r 被解释为头实体向量 $h$ 与尾实体向 量 $t$ 之间的平移. 因此, 嵌入的实体 $h$ 和 $t$ 可以通过平移向量 $r$ 以低误差连接, 即满足$h+r\approx t$:  , 图 2(a) 为该方法 的简洁表示. 对于每个三元组  , TransE 定义了如下的评分函数:$$f_r\left(h,t\right)=-\left\|\mathbf{h}+\mathbf{r}-\mathbf{t}\right\|_{1/2}$$
缺点:TransE 在处理复杂关系建模( 1-N, N-1 和 N-N)时性能降低, 这与其模型的假设有密切关系.

改善:
Point-Wise 欧氏空间广泛应用于表示实体和关系, 在向量或矩阵空间中投影关系嵌入, 或者捕捉关系交互.
#### TransH
TransH 模型使得一个实体在涉及不同关系时具有分布式表示。
TransH 将实体建模为向量, 将每个关系 $r$ 建模为法向量为$\mathbf{w}_{r}$的关系特定超平面上的向量 $r,r\in \mathbb{R}^d$ . 具体来说, 对于一个三元组 , TransH 首先将头实体向量 $h$ 与尾实体向量 $t$ 沿法线$\mathbf{w}_{r}$  投影到关系 $r$ 对应的超平面上, 投影分别记为 $\mathbf{h}_{\perp}$和$\mathbf{t}_{\perp}$ , 表示如下:$$\mathbf{h}_\perp=\mathbf{h}-\mathbf{w}_r^\top\mathbf{h}\mathbf{w}_{r}\qquad\mathbf{t}_\perp=\mathbf{t}-\mathbf{w}_r^\top\mathbf{t}\mathbf{w}_r$$
如果三元组$(h,r,t)$成立，那么就会有$\mathbf{h}_{\perp}+\mathbf{r} \approx t$,假设投影在超平面上由 $r$ 以低误差连接, 则 TransH 的评分函数定义为:$$f_{r}(h,t)=-\|\mathbf{h}_{\perp}+\mathbf{r}-\mathbf{t}_{\perp}\|_{2}^{2}$$
#### TransR
考虑到关系和实体是完全不同的对象.:一个实体是多种属性的综合体, 而各种关系关注实体的不同属性. 因此, 某些相似的实体在实体空间中彼此接近, 而在某些特定属性上不同, 在对应的关系空间中应彼此远离。
TransR 的基本思想: 对于每个三元组$(h,r,t)$  , 首先将头、尾实体向量向 关系 r 空间投影, 使得原来在实体空间中与头、尾实体相似的实体在关系 r 空间中被区分开.$$\mathbf{h}_\perp=\mathbf{M}_r\mathbf{h}\qquad \mathbf{t}_\perp=\mathbf{M}_r\mathbf{t}$$
其中$\mathbf{M}_{r}$是实体空间到关系空间的投影矩阵。TransR的评分函数为:
$$f_r\left(h,t\right)=-\|\mathbf{h}_\perp+\mathbf{r}-\mathbf{t}_\perp\|_2^2$$

#### TransD
TransR的缺点:
- ① 对于关系 r, 头、尾 实体共享相同的投影矩阵 , 忽略了头、尾实体不同的类型和属性;
-  ② 投影操作是实体与关系之间的交互过程, 因此, 投影矩阵仅由关系决定是不合理的;
-  ③ 与 TransE 和 TransH 相比, 矩阵-向量乘法使 TransR 模型参数急剧增 加, 因此, TransR 难以应用于大规模知识图谱

考虑到实体与关系的不同和 三元组中 头与尾 的不同，因此对于三元组和头和尾应该有不同的投影矩阵。因此TranD中的实体和关系都是由两个向量来表示: $$\mathbf{h},\mathbf{w}_{h},\mathbf{t},\mathbf{w}_{t},r,\mathbf{w}_{r}$$
而每个头或者是尾的两个向量通过一个投影矩阵来实现转换:
$$\mathbf{M}_{rh}=\mathbf{w}_{r}\mathbf{w}_{h}^⊤+\mathbf{I}^{k\times d},\mathbf{M}_{rt}=\mathbf{w}_{r}\mathbf{w}_{t}^⊤+\mathbf{I}^{k\times d}
$$
![[Pasted image 20240328174917.png]]
TransD评分函数:
$$f_{r}(h,t)=-\|\mathbf{hM}_{rh}+\mathbf{r}-\mathbf{tM}_{rt}\|_{2}^{2}$$
#### STransE
将两个简单的关系预测模型 SE 与 TransE 进行组合, 提出了一个新的嵌入模型 STransE, 该模型将每个实体表示为一个低维向量, 并通过两个矩阵和一个平移向量表示每个关系. 其评分函数 定义如下:
$$f_{r}\left(h,t\right)=\left\|\mathbf{M}_{r,1}\mathbf{h}+\mathbf{r}-\mathbf{M}_{r,2}\mathbf{t}\right\|_{1/2}$$
#### TanSparse
- 异质性 :异质性指知识库中一些关系 连接许多实体对, 而另一些关系则不连接 
- 不平衡性 :不平衡性指一个关系中头实体与尾实体的数目可能不同
TranSparse 模型可以处理这两个问题,  , 它有 TranSparse(share) 与 TranSparse(separate) 两个版本.
TranSparse 模型中投影矩阵的稀疏度由关系连接的实体对数量决定。 
具体来说, TranSparse 为每个关系 $r$ 设置了稀疏投影矩阵 $\mathbf{M}_{r}^{l}(\theta)_{r}\in \mathbb{R}^{k \times d}$ 和平移向量 $r$ ,  则投影矩阵 的稀疏度 定义为:$$\theta_{r}^{l} =1-(1-\theta_{min}) \frac{N_{r}^{l}}{N_{r}^*}$$其中$l\in \{h,t\}$,$N_{r}^l$表示关系 $r$ 连接的头/尾实体对数量, $N_{r}^{l*}$表示它们的最大数量,  $\theta_{min}\in [0,1]$是计算稀疏度的超参数。
每个关系有两个不同的稀疏投影矩阵, 分别用于头实体与尾实体。稀疏度由关系连接的头 (尾) 实体数量确定。(在share模型中，头实体和尾实体共享一个参数)
之后会实体向量进行投影:
$$\mathbf{h}_\perp=\mathbf{M}_r^h\left(\theta_r^h\right)\mathbf{h},\mathbf{t}_\perp=\mathbf{M}_r^t\left(\theta_r^t\right)\mathbf{t}$$
#### TransM
TransM: TransM将每个事实三元组 与特定关系权重 相关联.
核心思想是, 在学习 KG 表示时, **不同的关系可能具有不同的重要性**. 相应的评分函数定义为$$f_r(h,t)=w_r||\mathbf{h}+\mathbf{r}-\mathbf{t}||_{1/2}$$
![[Pasted image 20240328210145.png]]

#### TransA
Xiao 等人认为 TransE 及其之后的扩展模型存在两个主要问题
- ① 复杂的关系总是导致复杂的 嵌入拓扑, 而球形等势超曲面的灵活性不足以表征拓扑结构.
- ② 损失函数过于简化, 实体和关系向量的每个维度 同等考虑, 带来大量噪声并降低了性能.

为此, Xiao 等人提出了一种基于自适应和灵活度量的嵌入方法 TransA.
TransA 利用绝对损失的自适应马氏距离取代相对不够灵活的欧几里德距离  评分函数定义为$$f_{r}\left(h,t\right)=\left(\left|\mathbf{h}+\mathbf{r}-\mathbf{t}\right|\right)^{\mathrm{T}}\mathbf{M}_{r}\left(\left|\mathbf{h}+\mathbf{r}-\mathbf{t}\right|\right)$$
其中，$\:(|\mathbf{h}+\mathbf{r}-\mathbf{t}|)=(|h_1+r_1-t_1|,|h_2+r_2-t_2|,\ldots,|h_n+r_n-t_n|),\:\mathbf{h},\mathbf{t},\mathbf{r}\in\mathbb{R}^d,\:\mathbf{M}_r\in\mathbb{R}^{d\times d}$是与自适应度量相对应的关系特定的对称非负权重矩阵
TransA 采用椭圆等势面代替球形等势面, 可以更好地表示由复杂关系引起的复杂嵌入拓扑. 此外, TransA 可 以被视为加权转换后的特征维数, 抑制了来自无关维度的噪声

#### TransAt
TransAt: Qian 认为人类对关系的认知遵循一种层次化规律, 并且实体之间存在类别区分, 提出链接预测过程包含两个阶段,:
- 第一阶段, 考虑通过实体的某些属性分析候选实体类别是否合理, 从合理的类别中收集候选实体: 
- 第二阶段, 对于那些可能的三元组组合, 关注实体的细粒度属性以区分它们与特定关系的联系. 
这个过程中除了学习嵌入之外还引入了学习关系相关候选对象与关系相关注意力两个任务. 而以往的模型 (如 TransH, TransR, TranSparse) 无法学习细粒度的注意力. 由此, 提出 TransAt 模型来同时学习嵌入, 关系相关候选对象和关系相关注意力. TransAt 的评分 函数定义如下:$$f_r(h,t)=P_r\left(\sigma(\mathbf{r}_h)\mathbf{h}\right)+\mathbf{r}-P_r\left(\sigma(\mathbf{r}_t)\mathbf{t}\right)$$
